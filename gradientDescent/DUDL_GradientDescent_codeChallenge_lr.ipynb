{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 19/November/2022 - Saturday\n",
    "# Author: Virgilio Murillo Ochoa\n",
    "# personal github: Virgilio-AI\n",
    "# linkedin: https://www.linkedin.com/in/virgilio-murillo-ochoa-b29b59203\n",
    "# contact: virgiliomurilloochoa1@gmail.com\n",
    "# web: virgiliomurillo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52856a66",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1622461302252,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "JL_0UKJOj1YP"
   },
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b53d37",
   "metadata": {},
   "source": [
    "# Create the function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9306e57",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1622461302552,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "YwTBzVJsoKbg"
   },
   "outputs": [],
   "source": [
    "# define a range for x\n",
    "x = np.linspace(-2,2,2001)\n",
    "\n",
    "# function (as a function)\n",
    "def fx(x):\n",
    "  return 3*x**2 - 3*x + 4\n",
    "\n",
    "# derivative function\n",
    "def deriv(x):\n",
    "  return 6*x - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33f408",
   "metadata": {},
   "source": [
    "### G.D. using a fixed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911c60e",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1622461302553,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "yB8dmH-nvJ_D"
   },
   "outputs": [],
   "source": [
    "# random starting point\n",
    "localmin = np.random.choice(x,1)\n",
    "initval = localmin[:] # store the initial value\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = .01\n",
    "training_epochs = 50\n",
    "\n",
    "# run through training and store all the results\n",
    "modelparamsFixed = np.zeros((training_epochs,3))\n",
    "for i in range(training_epochs):\n",
    "  \n",
    "  # compute gradient\n",
    "  grad = deriv(localmin)\n",
    "\n",
    "  # non-adaptive learning rate\n",
    "  lr = learning_rate\n",
    "\n",
    "  # update parameter according to g.d.\n",
    "  localmin = localmin - lr*grad\n",
    "\n",
    "  # store the parameters\n",
    "  modelparamsFixed[i,:] = localmin,grad,lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26949eb4",
   "metadata": {},
   "source": [
    "### G.D. using a gradient-based learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e94d19",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622461302555,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "M22aVI6xVIbk"
   },
   "outputs": [],
   "source": [
    "# random starting point\n",
    "localmin = np.random.choice(x,1)\n",
    "initval = localmin[:] # store the initial value\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = .01\n",
    "training_epochs = 50\n",
    "\n",
    "# run through training and store all the results\n",
    "modelparamsGrad = np.zeros((training_epochs,3))\n",
    "for i in range(training_epochs):\n",
    "  \n",
    "  # compute gradient\n",
    "  grad = deriv(localmin)\n",
    "\n",
    "  # adapt the learning rate according to the gradient\n",
    "  lr = learning_rate*np.abs(grad)\n",
    "\n",
    "  # update parameter according to g.d.\n",
    "  localmin = localmin - lr*grad\n",
    "\n",
    "  # store the parameters\n",
    "  modelparamsGrad[i,:] = localmin,grad,lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34035ad",
   "metadata": {},
   "source": [
    "### G.D. using a time-based learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54166353",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622461302555,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "X6OWQULR30oV"
   },
   "outputs": [],
   "source": [
    "# redefine parameters\n",
    "learning_rate = .1\n",
    "localmin = initval\n",
    "\n",
    "# run through training and store all the results\n",
    "modelparamsTime = np.zeros((training_epochs,3))\n",
    "for i in range(training_epochs):\n",
    "  grad = deriv(localmin)\n",
    "  lr = learning_rate*(1-(i+1)/training_epochs)\n",
    "  localmin = localmin - lr*grad\n",
    "  modelparamsTime[i,:] = localmin,grad,lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282f94f",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3b0a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 1705,
     "status": "ok",
     "timestamp": 1622461304254,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "AInqnFtkVIeb",
    "outputId": "def67d5e-37ef-4577-aa75-c83e30390d9b"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(10,3))\n",
    "\n",
    "# generate the plots\n",
    "for i in range(3):\n",
    "  ax[i].plot(modelparamsFixed[:,i],'o-',markerfacecolor='w')\n",
    "  ax[i].plot(modelparamsGrad[:,i],'o-',markerfacecolor='w')\n",
    "  ax[i].plot(modelparamsTime[:,i],'o-',markerfacecolor='w')\n",
    "  ax[i].set_xlabel('Iteration')\n",
    "\n",
    "ax[0].set_ylabel('Local minimum')\n",
    "ax[1].set_ylabel('Derivative')\n",
    "ax[2].set_ylabel('Learning rate')\n",
    "ax[2].legend(['Fixed l.r.','Grad-based l.r.','Time-based l.r.'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fd977",
   "metadata": {},
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb46dbb",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1622461304254,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     },
     "user_tz": -120
    },
    "id": "m54Y_kYXiwO9"
   },
   "outputs": [],
   "source": [
    "# 1) Change the initial learning rate in the \"time\" experiment from .1 to .01. Do you still reach the same conclusion that\n",
    "#    dynamic learning rates are better than a fixed learning rate?\n",
    "# \n",
    "# 2) Compute the average of all time-based learning rates (see variable 'modelparamsTime'). Next, replace the fixed \n",
    "#    learning rate with the average over all dynamic learning rates. How does that affect the model's performance?\n",
    "# \n",
    "# 3) Going back to the original code (without the modifications above), you saw that the fixed learning rate model didn't\n",
    "#    get to the same local minimum. What happens if you increase the number of training epochs from 50 to 500? Does that \n",
    "#    improve the situation, and what does that tell you about the relationship between learning rate and training epochs?\n",
    "# \n",
    "# 4) The code here initializes the starting value as a random number, which will differ for each learning rate method.\n",
    "#    Is that appropriate or inappropriate for this experiment? Why? Change the code so that the starting value is the\n",
    "#    same for all three learning rate models.\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "executionInfo,colab,id,outputId,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
