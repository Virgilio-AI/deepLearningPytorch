{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 19/November/2022 - Saturday\n",
    "# Author: Virgilio Murillo Ochoa\n",
    "# personal github: Virgilio-AI\n",
    "# linkedin: https://www.linkedin.com/in/virgilio-murillo-ochoa-b29b59203\n",
    "# contact: virgiliomurilloochoa1@gmail.com\n",
    "# web: virgiliomurillo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ec16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# for printing out status reports\n",
    "import sys\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2243f",
   "metadata": {},
   "source": [
    "# Create temporal sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7dd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "N = 500\n",
    "\n",
    "time = torch.linspace(0,30*np.pi,N)\n",
    "data = torch.sin(time+torch.cos(time))\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(data,'ks-',markerfacecolor='w')\n",
    "plt.xlim([-5,N+4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f15397",
   "metadata": {},
   "source": [
    "# Create a class for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnnnet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # RNN Layer\n",
    "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
    "    \n",
    "    # linear layer for output\n",
    "    self.out = nn.Linear(num_hidden,1)\n",
    "  \n",
    "  def forward(self, x, h):\n",
    "    \n",
    "    # run through the RNN layer\n",
    "    y,hidden = self.rnn(x,h)\n",
    "    \n",
    "    # and the output (linear) layer\n",
    "    y = self.out(y)\n",
    "    \n",
    "    return y,hidden.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_size =  1 # \"channels\" of data\n",
    "num_hidden =  9 # breadth of model (number of units in hidden layers)\n",
    "num_layers =  1 # depth of model (number of \"stacks\" of hidden layers)\n",
    "seqlength  = 30 # number of datapoints used for learning in each segment\n",
    "batchsize  =  1 # Note: the training code is actually hard-coded to organize data into batchsize=1\n",
    "\n",
    "# create an instance of the model and inspect\n",
    "net = rnnnet()\n",
    "\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "y,h = net(X,None) # None is for empty hidden state input\n",
    "print(X.shape)\n",
    "print(y.shape) # note: one output per sequence element; generally, we take the final output to force a \"many-to-one\" design.\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04720b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it enough data?\n",
    "\n",
    "plt.plot(data[:seqlength],'ks-',markerfacecolor='w')\n",
    "plt.title(f'First {seqlength} data points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with some data\n",
    "somedata = data[:seqlength].view(seqlength,1,1)\n",
    "y = net(somedata,None)\n",
    "\n",
    "# grab the final predicted value from the output (first element of tuple output of net)\n",
    "finalValue = y[0][-1]\n",
    "\n",
    "lossfun = nn.MSELoss()\n",
    "lossfun(finalValue,data[seqlength].view(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a66c9a",
   "metadata": {},
   "source": [
    "# Train the model and show performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training epochs\n",
    "numepochs = 30\n",
    "\n",
    "# create a new instance of the model (and optimizer!)\n",
    "net = rnnnet()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=.001)\n",
    "\n",
    "\n",
    "\n",
    "# initialize losses\n",
    "losses = np.zeros(numepochs)\n",
    "signaccuracy = np.zeros(numepochs)\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over data segments\n",
    "  seglosses = []\n",
    "  segacc    = []\n",
    "  hiddenstate = None\n",
    "\n",
    "  for timei in range(N-seqlength):\n",
    "\n",
    "    # grab a snippet of data\n",
    "    X = data[timei:timei+seqlength].view(seqlength,1,1)\n",
    "    y = data[timei+seqlength].view(1,1)\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat,hiddenstate = net(X,hiddenstate)\n",
    "    finalValue = yHat[-1]\n",
    "    loss = lossfun(finalValue,y) # compare final value of output\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss from this segment\n",
    "    seglosses.append(loss.item())\n",
    "  \n",
    "  # average losses from this epoch\n",
    "  losses[epochi] = np.mean(seglosses)\n",
    "  \n",
    "  msg = f'Finished epoch {epochi+1}/{numepochs}'\n",
    "  sys.stdout.write('\\r' + msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's see how the model did!\n",
    "\n",
    "plt.plot(losses,'s-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now test the network!\n",
    "\n",
    "h = np.zeros((N,num_hidden))\n",
    "\n",
    "yHat = np.zeros(N)\n",
    "hh = None\n",
    "for timei in range(N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = data[timei:timei+seqlength].view(seqlength,1,1)\n",
    "\n",
    "  # forward pass and loss\n",
    "  yy,hh = net(X,hh)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "  h[timei+seqlength,:] = hh.detach()\n",
    "\n",
    "\n",
    "## plot!\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].plot(data,'bs-',label='Actual data',markersize=3)\n",
    "ax[0].plot(yHat,'ro-',label='Predicted',markersize=3)\n",
    "ax[0].set_ylim([-1.1,1.1])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(data-yHat,'k^')\n",
    "ax[1].set_ylim([-1.1,1.1])\n",
    "ax[1].set_title('Errors')\n",
    "\n",
    "ax[2].plot(data[seqlength:],yHat[seqlength:],'mo',markersize=3)\n",
    "ax[2].set_xlabel('Real data')\n",
    "ax[2].set_ylabel('Predicted data')\n",
    "r = np.corrcoef(data[seqlength:],yHat[seqlength:])\n",
    "ax[2].set_title(f\"r={r[0,1]:.2f} (NO Simpson's paradox!)\")\n",
    "\n",
    "plt.suptitle('Performance on training data',fontweight='bold',fontsize=20,y=1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the hidden \"states\" (units activations)\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.plot(h,'s-',markersize=3)\n",
    "plt.xlabel('Sequence index')\n",
    "plt.ylabel('State value (a.u.)')\n",
    "plt.title('Each line is a different hidden unit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weights for the input->hidden layers\n",
    "plt.bar(range(num_hidden),net.rnn.weight_ih_l0.detach())\n",
    "plt.ylabel('Weight value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabe462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69860b0b",
   "metadata": {},
   "source": [
    "# Test with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new data (orange case: different frequency)\n",
    "time = torch.linspace(0,10*np.pi,N)\n",
    "newdata = torch.sin(time+torch.cos(time))\n",
    "\n",
    "# Create new data (red case: different function)\n",
    "time = torch.linspace(0,30*np.pi,N)\n",
    "newdata = torch.sin(time+torch.sin(time))\n",
    "\n",
    "\n",
    "\n",
    "# loop over time and predict each subsequent value\n",
    "yHat = np.zeros(N)\n",
    "h = None\n",
    "for timei in range(N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = newdata[timei:timei+seqlength].view(seqlength,1,1)\n",
    "\n",
    "  # forward pass and loss (don't need hidden states here)\n",
    "  yy,h = net(X,h)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "\n",
    "\n",
    "# plotting\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].plot(newdata,'bs-',label='Actual data',markersize=3)\n",
    "ax[0].plot(yHat,'ro-',label='Predicted',markersize=3)\n",
    "ax[0].set_ylim([-1.1,1.1])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(newdata-yHat,'k^',markersize=3)\n",
    "ax[1].set_ylim([-1.1,1.1])\n",
    "ax[1].set_title('Errors')\n",
    "\n",
    "ax[2].plot(newdata[seqlength:],yHat[seqlength:],'mo',markersize=3)\n",
    "ax[2].set_xlabel('Real data')\n",
    "ax[2].set_ylabel('Predicted data')\n",
    "r = np.corrcoef(newdata[seqlength:],yHat[seqlength:])\n",
    "ax[2].set_title(f\"r={r[0,1]:.2f}\")\n",
    "\n",
    "plt.suptitle('Performance on unseen test data',fontweight='bold',fontsize=20,y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9891ef09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37ae530d",
   "metadata": {},
   "source": [
    "# Longer-term extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using original data\n",
    "\n",
    "# create a signal 2x as long\n",
    "yHat = torch.zeros(2*N) # torch, not np!\n",
    "yHat[:N] = data\n",
    "h = None\n",
    "\n",
    "for timei in range(2*N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = yHat[timei:timei+seqlength].view(seqlength,1,1)\n",
    "  \n",
    "  # forward pass and loss\n",
    "  yy,h = net(X,h)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "\n",
    "\n",
    "\n",
    "# convert back to np for plotting\n",
    "yHat = yHat.detach()\n",
    "\n",
    "# plotting\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.plot(data,'bs-',label='Actual data',markersize=3)\n",
    "plt.plot(yHat,'ro-',label='Predicted',markersize=3)\n",
    "plt.ylim([-1.1,1.1])\n",
    "plt.legend()\n",
    "plt.title('Performance on extrapolated data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda62c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d766d2",
   "metadata": {},
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Extrapolation was awful! Maybe the model is too simple? Try increasing the sequence length and the number\n",
    "#    of hidden units. Does that help the extrapolation?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0742c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
