{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 19/November/2022 - Saturday\n",
    "# Author: Virgilio Murillo Ochoa\n",
    "# personal github: Virgilio-AI\n",
    "# linkedin: https://www.linkedin.com/in/virgilio-murillo-ochoa-b29b59203\n",
    "# contact: virgiliomurilloochoa1@gmail.com\n",
    "# web: virgiliomurillo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# for importing data\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807ac0d",
   "metadata": {},
   "source": [
    "# Import a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba96432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transform = T.Compose([ T.ToTensor(), # normalizes to range [0,1]\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) # further normalization\n",
    "                       ])\n",
    "\n",
    "# import the data and simultaneously apply the transform\n",
    "trainset = torchvision.datasets.STL10(root='./data', download=True, split='train', transform=transform)\n",
    "testset  = torchvision.datasets.STL10(root='./data', download=True, split='test',  transform=transform)\n",
    "\n",
    "# transform to dataloaders\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(trainset,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(testset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2432a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the shape of the datasets\n",
    "print('Data shapes (train/test):')\n",
    "print( trainset.data.shape )\n",
    "print( testset.data.shape )\n",
    "\n",
    "# and the range of pixel intensity values\n",
    "print('\\nData value range:')\n",
    "print( (np.min(trainset.data),np.max(trainset.data)) )\n",
    "\n",
    "# the unique categories\n",
    "print('\\nData categories:')\n",
    "print( trainset.classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uh oh! It looks like the images are the wrong dimensions!\n",
    "# They need to be 3x96x96\n",
    "# And they are not normalized!\n",
    "\n",
    "# but...\n",
    "X,y = next(iter(train_loader))\n",
    "\n",
    "# try again\n",
    "print('Data shapes (train/test):')\n",
    "print( X.data.shape )\n",
    "\n",
    "# and the range of pixel intensity values\n",
    "print('\\nData value range:')\n",
    "print( (torch.min(X.data),torch.max(X.data),torch.mean(X.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the data\n",
    "plt.hist(X.data.numpy().flatten(),100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a few random images\n",
    "\n",
    "fig,axs = plt.subplots(4,4,figsize=(10,10))\n",
    "\n",
    "for (i,ax) in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract that image (need to transpose it back to 32x32x3)\n",
    "  pic = X.data[i].numpy().transpose((1,2,0))\n",
    "  pic = pic-np.min(pic) # undo normalization\n",
    "  pic = pic/np.max(pic)\n",
    "  \n",
    "  # and its label\n",
    "  label = trainset.classes[y[i]]\n",
    "\n",
    "  # and show!\n",
    "  ax.imshow(pic)\n",
    "  ax.text(0,0,label,ha='left',va='top',fontweight='bold',color='k',backgroundcolor='y')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9beb1e",
   "metadata": {},
   "source": [
    "# Import and inspect the VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggnet = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect this network\n",
    "vggnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(vggnet.to(device),(3,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a763d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers (final layer changed later)\n",
    "for p in vggnet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ef0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the final layer (this time soft-coded!)\n",
    "vggnet.classifier[6] = nn.Linear(vggnet.classifier[6].in_features,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the model to the GPU (if using)\n",
    "vggnet.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb6eb5",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(vggnet.parameters(),lr=0.001,momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6b413",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "numepochs = 10\n",
    "\n",
    "# initialize losses\n",
    "trainLoss = torch.zeros(numepochs)\n",
    "testLoss  = torch.zeros(numepochs)\n",
    "trainAcc  = torch.zeros(numepochs)\n",
    "testAcc   = torch.zeros(numepochs)\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over training data batches\n",
    "  vggnet.train() # switch to train mode\n",
    "  batchLoss = []\n",
    "  batchAcc  = []\n",
    "  for X,y in train_loader:\n",
    "\n",
    "    # push data to GPU\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = vggnet(X)\n",
    "    loss = lossfun(yHat,y)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss and accuracy from this batch\n",
    "    batchLoss.append(loss.item())\n",
    "    batchAcc.append( torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "  # end of batch loop...\n",
    "\n",
    "  # and get average losses and accuracies across the batches\n",
    "  trainLoss[epochi] = np.mean(batchLoss)\n",
    "  trainAcc[epochi]  = 100*np.mean(batchAcc)\n",
    "\n",
    "\n",
    "  #### test performance (here done in batches!)\n",
    "  vggnet.eval() # switch to test mode\n",
    "  batchAcc  = []\n",
    "  batchLoss = []\n",
    "  for X,y in test_loader:\n",
    "\n",
    "    # push data to GPU\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward pass and loss\n",
    "    with torch.no_grad():\n",
    "      yHat = vggnet(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "    \n",
    "    # loss and accuracy from this batch\n",
    "    batchLoss.append(loss.item())\n",
    "    batchAcc.append( torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "  # end of batch loop...\n",
    "\n",
    "  # and get average losses and accuracies across the batches\n",
    "  testLoss[epochi] = np.mean(batchLoss)\n",
    "  testAcc[epochi]  = 100*np.mean(batchAcc)\n",
    "\n",
    "  # print out a status update\n",
    "  print(f'Finished epoch {epochi+1}/{numepochs}. Test accuracy = {testAcc[epochi]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd55231",
   "metadata": {},
   "source": [
    "# Visualize the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'o-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss (MSE)')\n",
    "ax[0].set_title('Model loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model train/test accuracy: {trainAcc[-1]:.2f}/{testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.suptitle('Pretrained VGG-16 on STL10 data',fontweight='bold',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40217aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a few random images\n",
    "\n",
    "X,y = next(iter(test_loader))\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "vggnet.eval()\n",
    "predictions = torch.argmax( vggnet(X) ,axis=1)\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(4,4,figsize=(10,10))\n",
    "\n",
    "for (i,ax) in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract that image (need to transpose it back to 96x96x3)\n",
    "  pic = X.data[i].cpu().numpy().transpose((1,2,0))\n",
    "  pic = pic-np.min(pic) # undo normalization\n",
    "  pic = pic/np.max(pic)\n",
    "  \n",
    "  # show the image\n",
    "  ax.imshow(pic)\n",
    "  \n",
    "  \n",
    "  # label and true class\n",
    "  label = trainset.classes[predictions[i]]\n",
    "  truec = trainset.classes[y[i]]\n",
    "  title = f'Pred: {label}  -  true: {truec}'\n",
    "\n",
    "  # set the title with color-coded accuracy\n",
    "  titlecolor = 'g' if truec==label else 'r'\n",
    "  ax.text(48,90,title,ha='center',va='top',fontweight='bold',color='k',backgroundcolor=titlecolor,fontsize=8)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c61923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
