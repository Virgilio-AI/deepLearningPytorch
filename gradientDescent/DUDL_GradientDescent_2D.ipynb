{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 19/November/2022 - Saturday\n",
    "# Author: Virgilio Murillo Ochoa\n",
    "# personal github: Virgilio-AI\n",
    "# linkedin: https://www.linkedin.com/in/virgilio-murillo-ochoa-b29b59203\n",
    "# contact: virgiliomurilloochoa1@gmail.com\n",
    "# web: virgiliomurillo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef060f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sym # sympy to compute the partial derivatives\n",
    "\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853d52c",
   "metadata": {},
   "source": [
    "# Gradient descent in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c956ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"peaks\" function\n",
    "def peaks(x,y):\n",
    "  # expand to a 2D mesh\n",
    "  x,y = np.meshgrid(x,y)\n",
    "  \n",
    "  z = 3*(1-x)**2 * np.exp(-(x**2) - (y+1)**2) \\\n",
    "      - 10*(x/5 - x**3 - y**5) * np.exp(-x**2-y**2) \\\n",
    "      - 1/3*np.exp(-(x+1)**2 - y**2)\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the landscape\n",
    "x = np.linspace(-3,3,201)\n",
    "y = np.linspace(-3,3,201)\n",
    "\n",
    "Z = peaks(x,y)\n",
    "\n",
    "# let's have a look!\n",
    "plt.imshow(Z,extent=[x[0],x[-1],y[0],y[-1]],vmin=-5,vmax=5,origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create derivative functions using sympy\n",
    "\n",
    "sx,sy = sym.symbols('sx,sy')\n",
    "\n",
    "sZ = 3*(1-sx)**2 * sym.exp(-(sx**2) - (sy+1)**2) \\\n",
    "      - 10*(sx/5 - sx**3 - sy**5) * sym.exp(-sx**2-sy**2) \\\n",
    "      - 1/3*sym.exp(-(sx+1)**2 - sy**2)\n",
    "\n",
    "\n",
    "# create functions from the sympy-computed derivatives\n",
    "df_x = sym.lambdify( (sx,sy),sym.diff(sZ,sx),'sympy' )\n",
    "df_y = sym.lambdify( (sx,sy),sym.diff(sZ,sy),'sympy' )\n",
    "\n",
    "df_x(1,1).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7538b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random starting point (uniform between -2 and +2)\n",
    "localmin = np.random.rand(2)*4-2 # also try specifying coordinates\n",
    "startpnt = localmin[:] # make a copy, not re-assign\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = .01\n",
    "training_epochs = 1000\n",
    "\n",
    "# run through training\n",
    "trajectory = np.zeros((training_epochs,2))\n",
    "for i in range(training_epochs):\n",
    "  grad = np.array([ df_x(localmin[0],localmin[1]).evalf(), \n",
    "                    df_y(localmin[0],localmin[1]).evalf() \n",
    "                  ])\n",
    "  localmin = localmin - learning_rate*grad  # add _ or [:] to change a variable in-place\n",
    "  trajectory[i,:] = localmin\n",
    "\n",
    "\n",
    "print(localmin)\n",
    "print(startpnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look!\n",
    "plt.imshow(Z,extent=[x[0],x[-1],y[0],y[-1]],vmin=-5,vmax=5,origin='lower')\n",
    "plt.plot(startpnt[0],startpnt[1],'bs')\n",
    "plt.plot(localmin[0],localmin[1],'ro')\n",
    "plt.plot(trajectory[:,0],trajectory[:,1],'r')\n",
    "plt.legend(['rnd start','local min'])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254a11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ed9e072",
   "metadata": {},
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Modify the code to force the initial guess to be [0,1.4]. Does the model reach a reasonable local minimum?\n",
    "# \n",
    "# 2) Using the same starting point, change the number of training epochs to 10,000. Does the final solution differ from\n",
    "#    using 1000 epochs? \n",
    "# \n",
    "# 3) (Again with the same starting location) Change the learning to .1 (1000 epochs). What do you notice about the trajectory?\n",
    "#    Try again with the learning rate set to .5, and then to .00001.\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
