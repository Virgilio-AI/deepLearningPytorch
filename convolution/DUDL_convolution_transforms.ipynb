{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a46c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 19/November/2022 - Saturday\n",
    "# Author: Virgilio Murillo Ochoa\n",
    "# personal github: Virgilio-AI\n",
    "# linkedin: https://www.linkedin.com/in/virgilio-murillo-ochoa-b29b59203\n",
    "# contact: virgiliomurilloochoa1@gmail.com\n",
    "# web: virgiliomurillo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a40364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "# NEW!\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878793b",
   "metadata": {},
   "source": [
    "# Import a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b33e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of datasets that come with torchvision: https://pytorch.org/vision/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d253a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the CIFAR10 dataset\n",
    "cdata = torchvision.datasets.CIFAR10(root='cifar10', download=True)\n",
    "\n",
    "print(cdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f825731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the shape of the dataset\n",
    "print( cdata.data.shape )\n",
    "\n",
    "# the unique categories\n",
    "print( cdata.classes )\n",
    "\n",
    "# .targets is a list of targets converted to ints\n",
    "print( len(cdata.targets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a few random images\n",
    "\n",
    "fig,axs = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "\n",
    "  # select a random picture\n",
    "  randidx = np.random.choice(len(cdata.targets))\n",
    "\n",
    "  # extract that image\n",
    "  pic = cdata.data[randidx,:,:,:]\n",
    "  # and its label\n",
    "  label = cdata.classes[cdata.targets[randidx]]\n",
    "\n",
    "  # and show!\n",
    "  ax.imshow(pic)\n",
    "  ax.text(16,0,label,ha='center',fontweight='bold',color='k',backgroundcolor='y')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f60fb2",
   "metadata": {},
   "source": [
    "# Apply some transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = T.Compose([ T.ToTensor(),\n",
    "                 T.Resize(32*4),\n",
    "                 T.Grayscale(num_output_channels=1)  ])\n",
    "\n",
    "# include the transform in the dataset\n",
    "cdata.transform = Ts\n",
    "\n",
    "# you can also apply the transforms immediately when loading in the data\n",
    "# cdata = torchvision.datasets.CIFAR10(root='cifar10', download=True, transform=Ts)\n",
    "\n",
    "\n",
    "# Important! Adding a transform doesn't change the image data:\n",
    "print(cdata.data[123,:,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the transform\n",
    "\n",
    "# option 1a: apply the transform \"externally\" to an image\n",
    "img1 = Ts( cdata.data[123,:,:,:] )\n",
    "\n",
    "# option 1b: use the embedded transform\n",
    "img2 = cdata.transform( cdata.data[123,:,:,:] )\n",
    "\n",
    "# let's see what we've done!\n",
    "fig,ax = plt.subplots(1,3,figsize=(10,3))\n",
    "ax[0].imshow(cdata.data[123,:,:,:])\n",
    "ax[1].imshow(torch.squeeze(img1))\n",
    "ax[2].imshow(torch.squeeze(img2),cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note about ToTensor() and normalization:\n",
    "??T.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a6765b3",
   "metadata": {},
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed783a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) There are many other transforms available in torchvision: https://pytorch.org/vision/stable/transforms.html\n",
    "#    Many transformations are useful for data preparation and augmentation. We'll cover some of them later in the course,\n",
    "#    but for now, read about RandomCrop(), RandomHorizontalFlip(), and CenterCrop(). Then implement them to understand \n",
    "#    what they do to images.\n",
    "#    Tip: It's probably best to test these transforms separately, and on one test image, as we did above.\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
