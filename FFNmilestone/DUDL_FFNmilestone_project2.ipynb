{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ab2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 19/November/2022 - Saturday\n",
    "# Author: Virgilio Murillo Ochoa\n",
    "# personal github: Virgilio-AI\n",
    "# linkedin: https://www.linkedin.com/in/virgilio-murillo-ochoa-b29b59203\n",
    "# contact: virgiliomurilloochoa1@gmail.com\n",
    "# web: virgiliomurillo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data information:\n",
    "# https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "# Data source\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e878f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "\n",
    "# for DL modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for number-crunching\n",
    "import numpy as np\n",
    "\n",
    "# for dataset management\n",
    "import pandas as pd\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cca869",
   "metadata": {},
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8567ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "url  = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "data = pd.read_csv(url,sep=',',header=None)\n",
    "data.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','DISEASE']\n",
    "\n",
    "\n",
    "# data contain some ?'s; replace with NaN and drop those rows\n",
    "data = data.replace('?',np.nan).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distributions\n",
    "fig,ax = plt.subplots(1,figsize=(17,4))\n",
    "ax = sns.boxplot(data=data)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score the non-categorical columns\n",
    "cols2zscore = data.keys()\n",
    "cols2zscore = cols2zscore.drop(['sex','fbs','exang','DISEASE'])\n",
    "cols2zscore\n",
    "\n",
    "for c in cols2zscore:\n",
    "  d = pd.to_numeric(data[c]) # force to numeric (addresses some data-format issues)\n",
    "  data[c] = (d - d.mean())/d.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distributions again\n",
    "fig,ax = plt.subplots(1,figsize=(17,4))\n",
    "ax = sns.boxplot(data=data)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b896e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of all unique types of 'DISEASE'\n",
    "data['DISEASE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-code events to 0 (absent) and 1 (present)\n",
    "data['DISEASE'][data['DISEASE']>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa46bb",
   "metadata": {},
   "source": [
    "# Re-organize the data: train/test in DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from pandas dataframe to tensor\n",
    "dataT  = torch.tensor( data[data.keys().drop('DISEASE')].values ).float()\n",
    "labels = torch.tensor( data['DISEASE'].values ).float()\n",
    "\n",
    "print( dataT.shape )\n",
    "print( labels.shape )\n",
    "\n",
    "# we'll actually need the labels to be a \"matrix\"\n",
    "labels = labels[:,None]\n",
    "print( labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c70999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labels, test_size=50)\n",
    "\n",
    "# then convert them into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 20\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in train_loader:\n",
    "  print(X.shape,  y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b43c8",
   "metadata": {},
   "source": [
    "# Create a class for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8662bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the class\n",
    "class theNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### input layer\n",
    "    self.input = nn.Linear(13,32)\n",
    "    \n",
    "    ### hidden layers\n",
    "    self.fc1 = nn.Linear(32,64)\n",
    "    self.fc2 = nn.Linear(64,10)\n",
    "\n",
    "    ### output layer\n",
    "    self.output = nn.Linear(10,1)\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    x = F.relu( self.input(x) )\n",
    "    x = F.relu( self.fc1(x) )\n",
    "    x = F.relu( self.fc2(x) )\n",
    "    return self.output(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec889baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on a bit of data\n",
    "net = theNet()\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "print(yHat)\n",
    "\n",
    "# test the loss function\n",
    "lossfun = nn.BCEWithLogitsLoss()\n",
    "lossfun(yHat,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f908a0",
   "metadata": {},
   "source": [
    "# Train the model and show performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a fresh network\n",
    "net = theNet()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=.0001)\n",
    "lossfun = nn.BCEWithLogitsLoss() # try with different loss function\n",
    "\n",
    "\n",
    "# number of training epochs\n",
    "numepochs = 100\n",
    "\n",
    "\n",
    "# initialize losses and accuracies\n",
    "trainLoss = torch.zeros(numepochs)\n",
    "testLoss  = torch.zeros(numepochs)\n",
    "trainAcc  = torch.zeros(numepochs)\n",
    "testAcc   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over training data batches\n",
    "  batchLoss = []\n",
    "  for X,y in train_loader:\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = net(X)\n",
    "    loss = lossfun(yHat,y)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss from this batch\n",
    "    batchLoss.append(loss.item())\n",
    "    \n",
    "    # train accuracy\n",
    "    predictions = (torch.sigmoid(yHat)>.5).float()\n",
    "    trainAcc[epochi] = 100*torch.mean((predictions==y).float())\n",
    "\n",
    "  # end of batch loop...\n",
    "\n",
    "  # get average losses across the batches\n",
    "  trainLoss[epochi] = np.mean(batchLoss)\n",
    "\n",
    "\n",
    "  ## now for the test\n",
    "  X,y = next(iter(test_loader))\n",
    "  yHat = net(X)\n",
    "  \n",
    "  # test loss\n",
    "  loss = lossfun(yHat,y)\n",
    "  testLoss[epochi] = loss.item()\n",
    "  \n",
    "  # test accuracy\n",
    "  predictions = (torch.sigmoid(yHat)>.5).float()\n",
    "  testAcc[epochi] = 100*torch.mean((predictions==y).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'s-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679e931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
